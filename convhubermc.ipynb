{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33035,"status":"ok","timestamp":1696836126900,"user":{"displayName":"Talha Ahmed","userId":"17372384323512083426"},"user_tz":-300},"id":"QkewbYGcurVf","outputId":"10da4d48-8e12-4001-d652-864b9e977ded"},"outputs":[],"source":["# Note: Original saved in Tahir Sproj\n","\n","# Deep Learning Libraries\n","import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","import torch.utils.data as data\n","\n","# Data Manipulation and Analysis\n","import numpy as np\n","import pandas as pd\n","\n","# Data Visualization\n","import matplotlib\n","import matplotlib.pyplot as plt\n","\n","# File and System Interaction\n","import os\n","from pathlib import Path\n","import shutil\n","import torch.optim as optim\n","\n","\n","# Date and Time Handling\n","import time\n","import datetime\n","\n","# Linear Algebra\n","from torch import linalg as LA\n","\n","# Neural Architecture\n","try:\n","    from torchinfo import summary\n","except:\n","    # %pip install torchinfo\n","    from torchinfo import summary"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2\n","\n","from python_scripts import dataset_processing\n","from python_scripts import architecture\n","from python_scripts import revised_architecture\n","from python_scripts import training\n","from python_scripts import logs_and_results"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":9,"status":"aborted","timestamp":1696836126902,"user":{"displayName":"Talha Ahmed","userId":"17372384323512083426"},"user_tz":-300},"id":"zwYsPMqG68M6"},"outputs":[{"data":{"text/plain":["'cpu'"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# Setting up some global variables\n","\n","# ROOT = 'C:/Users/Talha/OneDrive - Higher Education Commission/Documents/GitHub/ConvHuberMC/HuberMC_Data'\n","ROOT = 'C:/Users/HP/GitHub Workspace/ConvHuberMC-Net/HuberMC_Data'\n","TRY = 'Try 1'\n","SESSION = 'Session 1'\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","device"]},{"cell_type":"markdown","metadata":{"id":"reS6gl1b1M70"},"source":["#### Model path of loading"]},{"cell_type":"markdown","metadata":{"id":"RGsjtUu7-iJ5"},"source":["Testing Training Loop"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":9,"status":"aborted","timestamp":1696836126902,"user":{"displayName":"Talha Ahmed","userId":"17372384323512083426"},"user_tz":-300},"id":"nOIBCr5gIr8Y"},"outputs":[],"source":["# Get parameters --> for convhubermc: c, lambda, sigma, mu, delta, tau\n","def get_default_param(gpu = True):\n","    params_net = {}\n","    params_net['size1'] = 150\n","    params_net['size2'] = 300\n","    params_net['rank'] = 10\n","    \n","    params_net['device'] = device\n","\n","    params_net['hubreg_iters'] = 2\n","    params_net['layers'] = 3\n","    params_net['kernel'] = (3, 3)\n","    \n","    params_net['CalInGPU'] = gpu\n","    \n","    return params_net"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# seed = 123\n","# torch.manual_seed(seed)\n","# target = (torch.randn(30, 50))\n","# input_tensor = target * torch.bernoulli(torch.full((30, 50), 0.2))\n","# model = architecture.UnfoldedNet_Huber(params = get_default_param(False))\n","\n","# criterion = nn.MSELoss()\n","# optimizer = torch.optim.Adam(model.parameters())\n","\n","# model.train()\n","# output = model(input_tensor)\n","\n","# loss = (criterion(output, target))/torch.square(torch.norm(target, p = 'fro'))\n","# optimizer.zero_grad()\n","# print(f'loss before backward: {loss}, loss.grad: {loss.requires_grad}')\n","# loss.backward()\n","# print(f'loss: {loss}')\n","# print(\"\\nGradients after one epoch:\")\n","# for name, param in model.named_parameters():\n","#     print(f'name: {name}\\t\\tgradient: {param.grad}')\n","# optimizer.step()"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# # Create a input_tensor of random indices\n","# shuffled_indices = torch.randperm(input_tensor.nelement())\n","\n","# # Index the original input_tensor with these shuffled indices\n","# shuffled_input_tensor = input_tensor.view(-1)[shuffled_indices].view(input_tensor.size())\n","\n","# output = model(shuffled_input_tensor)\n","\n","# loss = (criterion(output, target))/torch.square(torch.norm(target, p = 'fro'))\n","# optimizer.zero_grad()\n","# print(f'loss before backward: {loss}, loss.grad: {loss.requires_grad}')\n","# loss.backward()\n","# print(f'loss: {loss}')\n","# print(\"\\nGradients after one epoch:\")\n","# for name, param in model.named_parameters():\n","#     print(f'name: {name}\\t\\tgradient: {param.grad}')\n","# optimizer.step()"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# # Create a input_tensor of random indices\n","# shuffled_indices = torch.randperm(input_tensor.nelement())\n","\n","# # Index the original input_tensor with these shuffled indices\n","# shuffled_input_tensor = input_tensor.view(-1)[shuffled_indices].view(input_tensor.size())\n","\n","# output = model(shuffled_input_tensor)\n","\n","# loss = (criterion(output, target))/torch.square(torch.norm(target, p = 'fro'))\n","# optimizer.zero_grad()\n","# print(f'loss before backward: {loss}, loss.grad: {loss.requires_grad}')\n","# loss.backward()\n","# print(f'loss: {loss}')\n","# print(\"\\nGradients after one epoch:\")\n","# for name, param in model.named_parameters():\n","#     print(f'name: {name}\\t\\tgradient: {param.grad}')\n","# optimizer.step()"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["UnfoldedNet_Huber(\n","  (conv_layers): ModuleList(\n","    (0-449): 450 x Conv2dC(\n","      (convR): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    )\n","  )\n","  (huber_obj): Sequential(\n","    (0): Huber(\n","      (conv_layers): ModuleList(\n","        (0-449): 450 x Conv2dC(\n","          (convR): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        )\n","      )\n","    )\n","    (1): Huber(\n","      (conv_layers): ModuleList(\n","        (0-449): 450 x Conv2dC(\n","          (convR): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        )\n","      )\n","    )\n","    (2): Huber(\n","      (conv_layers): ModuleList(\n","        (0-449): 450 x Conv2dC(\n","          (convR): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        )\n","      )\n","    )\n","  )\n",")"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["model = revised_architecture.UnfoldedNet_Huber(params = get_default_param(False))\n","model"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# model.forward(torch.randn(150, 300) * torch.bernoulli(torch.full((150, 300), 0.2)))\n","# model.forward(torch.randn(30, 50) * torch.bernoulli(torch.full((30, 50), 0.2)))\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":["==========================================================================================\n","Layer (type:depth-idx)                   Output Shape              Param #\n","==========================================================================================\n","UnfoldedNet_Huber                        [150, 300]                --\n","├─Sequential: 1-1                        [150, 300]                --\n","│    └─Huber: 2-1                        [150, 300]                4,500\n","│    └─Huber: 2-4                        --                        (recursive)\n","│    │    └─ModuleList: 3-3              --                        (recursive)\n","│    └─Huber: 2-3                        [150, 300]                4,500\n","│    └─Huber: 2-4                        --                        (recursive)\n","│    │    └─ModuleList: 3-3              --                        (recursive)\n","│    └─Huber: 2-5                        [150, 300]                4,500\n","│    │    └─ModuleList: 3-3              --                        (recursive)\n","==========================================================================================\n","Total params: 17,990\n","Trainable params: 17,990\n","Non-trainable params: 0\n","Total mult-adds (Units.MEGABYTES): 27\n","==========================================================================================\n","Input size (MB): 0.18\n","Forward/backward pass size (MB): 21.60\n","Params size (MB): 0.02\n","Estimated Total Size (MB): 21.80\n","=========================================================================================="]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["summary(model, input_size = [150, 300])"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":653},"executionInfo":{"elapsed":415,"status":"error","timestamp":1696360284646,"user":{"displayName":"Talha Ahmed","userId":"17372384323512083426"},"user_tz":-300},"id":"bmMuNqIs97hm","outputId":"ebed6b71-2dc9-42fe-b8e7-399ecf985c27"},"outputs":[{"name":"stdout","output_type":"stream","text":["Project Name: Try 1 HuberMC-Net Q 20.0% DB 3.0\n","\n","Configuring Network...\n","Instantiating Model...\n","Model Instantiated...\n","\n","Parameters = \n","{'size1': 150, 'size2': 300, 'rank': 10, 'device': 'cpu', 'hubreg_iters': 2, 'layers': 3, 'kernel': (3, 3), 'CalInGPU': False}\n","\n","Epoch: 1, 2024-03-23 04:07:58, \n","\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[15], line 82\u001b[0m\n\u001b[0;32m     79\u001b[0m     log\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest time is \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m%\u001b[39m(endtime \u001b[38;5;241m-\u001b[39m startime))\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 82\u001b[0m     loss_mean \u001b[38;5;241m=\u001b[39m \u001b[43mtraining\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCalInGPU\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyper_param_net\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTrainInstances\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyper_param_net\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBatchSize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m     loss_val_mean \u001b[38;5;241m=\u001b[39m training\u001b[38;5;241m.\u001b[39mtest_step(net, val_loader, floss, CalInGPU, hyper_param_net[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValInstances\u001b[39m\u001b[38;5;124m'\u001b[39m], hyper_param_net[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValBatchSize\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# Update Record and Parameters\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\HP\\GitHub Workspace\\ConvHuberMC-Net\\python_scripts\\training.py:84\u001b[0m, in \u001b[0;36mtrain_step\u001b[1;34m(model, dataloader, loss_fn, optimizer, CalInGPU, TrainInstances, batch, inference)\u001b[0m\n\u001b[0;32m     82\u001b[0m inputs \u001b[38;5;241m=\u001b[39m D[mat]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     83\u001b[0m targets_L \u001b[38;5;241m=\u001b[39m L[mat]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 84\u001b[0m outputs_L \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m loss \u001b[38;5;241m=\u001b[39m (loss_fn(outputs_L, targets_L))\u001b[38;5;241m/\u001b[39mtorch\u001b[38;5;241m.\u001b[39msquare(torch\u001b[38;5;241m.\u001b[39mnorm(targets_L, p \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfro\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# loss = torch.square(torch.norm(targets_L, p = 'fro')) / loss_fn(outputs_L, targets_L)\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# loss = (loss_fn(outputs_L, targets_L)) / (targets_L.shape[0] * targets_L.shape[1])\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# loss = ((loss_val * loss_fn(outputs_L, targets_L)) / (targets_L.shape[0] * targets_L.shape[1])).item()\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\HP\\GitHub Workspace\\math491\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\HP\\GitHub Workspace\\math491\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\HP\\GitHub Workspace\\ConvHuberMC-Net\\python_scripts\\revised_architecture.py:244\u001b[0m, in \u001b[0;36mUnfoldedNet_Huber.forward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    237\u001b[0m \n\u001b[0;32m    238\u001b[0m     \u001b[38;5;66;03m# Now initalize the neural architecture of even number of layers where even numbered layers correspond to updating U and odd numbered\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;66;03m# Step 1: Compute Forward Pass through all the layers and predict ground truth matrix\u001b[39;00m\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;66;03m# print('c before call:', self.c)\u001b[39;00m\n\u001b[1;32m--> 244\u001b[0m     X, U, V \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhuber_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mU\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mV\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;66;03m# print('c after call:', self.c)\u001b[39;00m\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m U \u001b[38;5;241m@\u001b[39m V\n","File \u001b[1;32mc:\\Users\\HP\\GitHub Workspace\\math491\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\HP\\GitHub Workspace\\math491\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\HP\\GitHub Workspace\\math491\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[1;32mc:\\Users\\HP\\GitHub Workspace\\math491\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\HP\\GitHub Workspace\\math491\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\HP\\GitHub Workspace\\ConvHuberMC-Net\\python_scripts\\revised_architecture.py:176\u001b[0m, in \u001b[0;36mHuber.forward\u001b[1;34m(self, lst)\u001b[0m\n\u001b[0;32m    174\u001b[0m     rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_rows(X[:, j]) \u001b[38;5;66;03m# row indices for jth column\u001b[39;00m\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;66;03m# V[:, j: j + 1] = self.hubregv((V[:, j: j + 1], U[rows, :], X[rows, j: j + 1], self.conv_layers[j]))\u001b[39;00m\n\u001b[1;32m--> 176\u001b[0m     new_V_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhubregv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mV\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mU\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_layers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    177\u001b[0m     V \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((V[:, :j], new_V_col, V[:, j \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m:]), dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(U\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n","File \u001b[1;32mc:\\Users\\HP\\GitHub Workspace\\ConvHuberMC-Net\\python_scripts\\revised_architecture.py:103\u001b[0m, in \u001b[0;36mHuber.hubregv\u001b[1;34m(self, tup_arg)\u001b[0m\n\u001b[0;32m    101\u001b[0m r \u001b[38;5;241m=\u001b[39m y \u001b[38;5;241m-\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(X, beta)\n\u001b[0;32m    102\u001b[0m r_chi \u001b[38;5;241m=\u001b[39m psi(r \u001b[38;5;241m/\u001b[39m scale) \u001b[38;5;241m*\u001b[39m (r \u001b[38;5;241m/\u001b[39m scale) \u001b[38;5;241m-\u001b[39m rho(r \u001b[38;5;241m/\u001b[39m scale)\n\u001b[1;32m--> 103\u001b[0m scale \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mN\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr_chi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m r_pseu \u001b[38;5;241m=\u001b[39m psi(r \u001b[38;5;241m/\u001b[39m scale) \u001b[38;5;241m*\u001b[39m scale\n\u001b[0;32m    107\u001b[0m delta \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(X_plus_conv, r_pseu)\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Some settings for visualisation\n","matplotlib.use('Agg')\n","%matplotlib inline\n","\n","seed = 123\n","torch.manual_seed(seed)\n","\n","# Set parameters (including hyperparameters) and setting for saving/logging data\n","hyper_param_net = training.get_hyperparameter_grid('HuberMC-Net', TrainInstances = 20, ValInstances = 10, BatchSize = 5, ValBatchSize = 2, num_epochs = 20, learning_rate = 0.001)\n","params_net = get_default_param(gpu = False)\n","CalInGPU = params_net['CalInGPU']\n","\n","q_list = [0.2]\n","db_list = [3.0]\n","\n","for q in q_list:\n","    for db in db_list:\n","        # ProjectName = TRY + ' ' + logs_and_results.get_current_time() + ' ' + hyper_param_net['Model'] + ' ' + 'Sampling Rate: ' + logs_and_results.get_q_str(q) + ' and DB ' + logs_and_results.get_noise_str(db)\n","\n","        ProjectName = TRY + ' ' + hyper_param_net['Model'] + ' Q ' + logs_and_results.get_q_str(q) + ' DB ' + logs_and_results.get_noise_str(db)\n","        # Note: Removed time stamp from log file name as : not supported. Weird because this was not a problem in linux\n","\n","        # Get log file\n","        logfile = logs_and_results.get_modularized_record(ProjectName, q, db, 'Logs', hyper_param_net, params_net, ROOT, SESSION)\n","        with open(logfile, 'w', 1) as log:\n","            print('Project Name: %s\\n'%ProjectName)\n","            log.write('Project Name: %s\\n\\n'%ProjectName)\n","\n","            # Get Model\n","            net = training.get_model(params_net, hyper_param_net, log)\n","            print('\\nParameters = \\n%s\\n'%str(params_net))\n","            log.write('\\nParameters = \\n%s\\n\\n'%str(params_net))\n","\n","            #Loading data and creating dataloader for both test and training\n","            # print('Loading Data phase...')\n","            log.write('Loading phase...\\n')\n","            shape_dset = (params_net['size1'], params_net['size2'])\n","            \n","            train_loader, val_loader = dataset_processing.get_dataloaders(params_net = params_net, hyper_param_net = hyper_param_net, sampling_rate = q, db = db, ROOT = ROOT)\n","\n","            # print('Finished loading.\\n')\n","            log.write('Finished loading.\\n\\n')\n","\n","            # Some additional settings for training including loss, optimizer,\n","            # floss = nn.functional.mse_loss(reduction = 'sum')\n","            floss = nn.MSELoss()\n","            optimizer = torch.optim.Adam(net.parameters(), lr = hyper_param_net['Lr'])\n","            # scheduler2 =  torch.optim.lr_scheduler.StepLR(optimizer, step_size= 1, gamma = 0.97, verbose = True)\n","\n","            # Array for recording parameter values after each layer for each epoch etc\n","            outputs_L = revised_architecture.to_var(torch.zeros([shape_dset[0], shape_dset[1]]), CalInGPU) \n","            lossmean_vec = np.zeros((hyper_param_net['Epochs'], ))\n","            lossmean_val_vec = np.zeros((hyper_param_net['Epochs'], ))\n","\n","\n","            # dummy variable to monitor and record progress for loss\n","            minloss = np.inf\n","\n","            for epoch in range(hyper_param_net['Epochs']):\n","                print(f'Epoch: {epoch + 1}, {logs_and_results.get_current_time()}, \\n')\n","                log.write(logs_and_results.get_current_time() + '\\n\\n')\n","\n","                # Train and Test Steps. (Record every 5 epochs)\n","                if (epoch + 1) % 5 == 0:\n","                    # print('Loading and calculating training batches...')\n","                    log.write('Loading and calculating training batches...\\n')\n","                    startime = time.time()\n","                    loss_mean = training.train_step(net, train_loader, floss, optimizer, CalInGPU, hyper_param_net['TrainInstances'], hyper_param_net['BatchSize']) # remove alpha from train func\n","                    endtime = time.time()\n","                    # print('Training time is %f'%(endtime - startime))\n","                    log.write('Training time is %f'%(endtime - startime))\n","\n","                    # print('Loading and calculating validation batches...')\n","                    log.write('Loading and calculating validation batches...\\n')\n","                    startime = time.time()\n","                    loss_val_mean = training.test_step(net, val_loader, floss, CalInGPU, hyper_param_net['ValInstances'], hyper_param_net['ValBatchSize'])\n","                    endtime = time.time()\n","                    # print('Test time is %f'%(endtime - startime))\n","                    log.write('Test time is %f'%(endtime - startime))\n","\n","                else:\n","                    loss_mean = training.train_step(net, train_loader, floss, optimizer, CalInGPU, hyper_param_net['TrainInstances'], hyper_param_net['BatchSize'])\n","                    loss_val_mean = training.test_step(net, val_loader, floss, CalInGPU, hyper_param_net['ValInstances'], hyper_param_net['ValBatchSize'])\n","\n","                # Update Record and Parameters\n","                lossmean_vec[epoch] = loss_mean\n","                lossmean_val_vec[epoch] = loss_val_mean\n","\n","\n","                print('Epoch [%d/%d], Mean Training Loss:%.5e, Mean Validation Loss:%.5e'\n","                      %(epoch + 1, hyper_param_net['Epochs'], loss_mean, loss_val_mean))\n","\n","                # Update Log after every 5 epochs. Make a plot of MSE against epochs every 5 epochs. Save Model in whole/dict form every five epochs.\n","                if (epoch + 1) % 5 == 0:\n","                    print(f\"Saving Whole Model at Epochs: [{epoch + 1}/{hyper_param_net['Epochs']}]\")\n","                    model_whole_path = logs_and_results.get_modularized_record(ProjectName, q, db, 'Saved Models - Whole', hyper_param_net, params_net, ROOT, SESSION, current_epoch = epoch + 1)\n","                    # torch.save(net, model_whole_path)\n","                    print(f\"Saving Model Dict at Epochs: [{epoch + 1}/{hyper_param_net['Epochs']}]\")\n","                    model_state_dict_path = logs_and_results.get_modularized_record(ProjectName, q, db, 'Saved Models - Dict', hyper_param_net, params_net, ROOT, SESSION, current_epoch = epoch + 1)\n","                    # torch.save(net.state_dict(), model_state_dict_path)\n","\n","                    # print('Epoch [%d/%d], Mean Training Loss:%.5e, Mean Validation Loss:%.5e'\n","                    # %(epoch + 1, hyper_param_net['Epochs'], loss_mean, loss_val_mean))\n","                    # print('loss_lowrank_mean', loss_lowrank_mean)\n","                    # print('loss_val_lowrank_mean', loss_val_lowrank_mean)\n","                    # print(f'c: {c_list}, lamda: {lamda_list}, mu: {mu_list}')\n","\n","                    # log.write('loss_lowrank_mean %.5e\\n' %(loss_lowrank_mean))\n","                    # log.write('loss_val_lowrank_mean %.5e\\n' %(loss_val_lowrank_mean))\n","                    log.write('Epoch [%d/%d], Mean Training Loss:%.5e, Mean Validation Loss:%.5e\\n'\n","                              %(epoch + 1, hyper_param_net['Epochs'], loss_mean, loss_val_mean))\n","                    np.set_printoptions(precision = 3)\n","\n","                    if True or loss_val_mean < minloss:\n","                        # print('saved at [epoch%d/%d]'%(epoch + 1, hyper_param_net['Epochs']))\n","                        log.write('saved at [epoch%d/%d]\\n' %(epoch + 1, hyper_param_net['Epochs']))\n","                        minloss = min(loss_val_mean, minloss)\n","\n","            # Finish off by observing the minimum loss on validation set\n","\n","            #Print min loss\n","            # print('\\nMin Loss = %.4e'%np.min(lossmean_val_vec))\n","            log.write('\\nMin Loss = %.4e'%np.min(lossmean_val_vec))\n","\n","            # Plotting MSE vs Epoch and Saving it\n","\n","            # Get Directory where we have to save the plot\n","            dir = logs_and_results.get_modularized_record(ProjectName, q, db, 'Plots', hyper_param_net, params_net, ROOT, SESSION, current_epoch = epoch + 1)\n","            logs_and_results.plot_and_save_mse_vs_epoch(lossmean_vec, lossmean_val_vec, dir)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"}},"nbformat":4,"nbformat_minor":0}
