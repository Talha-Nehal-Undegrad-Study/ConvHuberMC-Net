{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33035,"status":"ok","timestamp":1696836126900,"user":{"displayName":"Talha Ahmed","userId":"17372384323512083426"},"user_tz":-300},"id":"QkewbYGcurVf","outputId":"10da4d48-8e12-4001-d652-864b9e977ded"},"outputs":[],"source":["# Deep Learning Libraries\n","import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","import torch.utils.data as data\n","\n","# Data Manipulation and Analysis\n","import numpy as np\n","import pandas as pd\n","import collections # A module providing alternative data structures like named tuples, defaultdict, Counter, etc., compared to built-in Python containers.\n","import random\n","\n","# Data Visualization\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import seaborn\n","\n","# File and System Interaction\n","import glob\n","import os\n","from pathlib import Path\n","import shutil\n","\n","# Scientific Computing and Math\n","import math\n","import cmath\n","\n","# Date and Time Handling\n","import time\n","import datetime\n","\n","# Linear Algebra\n","from torch import linalg as LA"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":327},"executionInfo":{"elapsed":11,"status":"error","timestamp":1696836126901,"user":{"displayName":"Talha Ahmed","userId":"17372384323512083426"},"user_tz":-300},"id":"79B6gFe38zuq","outputId":"f692e85f-826d-4670-a27b-60828627bf42"},"outputs":[],"source":["\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"aborted","timestamp":1696836126901,"user":{"displayName":"Talha Ahmed","userId":"17372384323512083426"},"user_tz":-300},"id":"xvQcO1ni5Urb"},"outputs":[],"source":["# # Get scripts from github\n","\n","# # Download it from GitHub\n","# try:\n","#   from py_scripts import convmc, dataset_processing, inference, logs_and_results, training\n","# except:\n","#   # Clone github to access data\n","#   !git clone https://github.com/TalhaAhmed2000/convmc-net.git\n","#   !mv convmc-net/python_scripts py_scripts\n","#   from py_scripts import convmc, dataset_processing, inference, logs_and_results, training"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"aborted","timestamp":1696836126901,"user":{"displayName":"Talha Ahmed","userId":"17372384323512083426"},"user_tz":-300},"id":"t9N8VwMpvq8Z"},"outputs":[],"source":["# !rm -r convmc-net\n","# !rm -r py_scripts"]},{"cell_type":"markdown","metadata":{"id":"Xs7CHSXOO88t"},"source":["## Dataset.py"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"aborted","timestamp":1696836126902,"user":{"displayName":"Talha Ahmed","userId":"17372384323512083426"},"user_tz":-300},"id":"FWtarXCH3mFY"},"outputs":[],"source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Fri Aug  3 13:29:11 2018\n","\n","@author: Yi Zhang\n","\"\"\"\n","\n","\n","\n","class Dataset:\n","    def __init__(self,folder=None,shuffle=None,prefix=None,shownum=10):\n","        self._folder=None\n","        if not folder is None:\n","            self._folder=folder\n","            self._flist=os.listdir(folder)\n","        if not prefix is None:\n","            tmp=[]\n","            for s in self._flist:\n","                if s.startswith(prefix):\n","                    tmp.append(s)\n","            self._flist=tmp\n","        self._flist.sort()\n","        if not shuffle is None:\n","            random.shuffle(self._flist,shuffle)\n","            print(self._flist[0:shownum])\n","\n","    def getnpz(self,fileind,arrind,folder=None):\n","        if folder is None:\n","            folder=self._folder\n","            flist=self._flist\n","        else:\n","            flist=os.listdir(folder)\n","        data=np.load(folder+flist[fileind],mmap_mode='r+')\n","        dlist=[]\n","        l=0\n","        for x in data:\n","            if l in arrind:\n","                dlist.append(data[x])\n","            l=l+1\n","        return dlist\n","\n","    def getmat(self,fileind,arrind,folder=None):\n","        if folder is None:\n","            folder=self._folder\n","            flist=self._flist\n","        else:\n","            flist=os.listdir(folder)\n","        data=loadmat(folder+flist[fileind])\n","        dlist=[]\n","        for x in arrind:\n","            dlist.append(data[x])\n","        return dlist\n","\n","\n","class Converter:\n","    def __init__(self):\n","        \"\"\"\n","        Preprocessing:\n","        1.concat: inv=False, concatenate real and imaginary parts in axis=-1\n","            inv=True, depart two parts in -1 axis into real and imaginary parts\n","        2.ch2: inv=False, concatenate real and imaginary parts in a new axis=0\n","            inv=True, depart two parts in 1 axis into real and imaginary parts\n","        3.stack: inv=False, stack real and imaginary parts in axis=-1\n","            inv=True, depart two parts in -1 axis into real and imaginary parts\n","        3.None: pass\n","        \"\"\"\n","        # self.pre={'concat':self.concat,'ch2':self.ch2,'stack':self.stack}\n","\n","    def np2torch(self,xnp,formlist):\n","        dlist=[]\n","        for i,x in enumerate(xnp):\n","            # if ('pre' in formlist[i]) and (formlist[i]['pre'] in self.pre):\n","            #     x=self.pre[formlist[i]['pre']](x,inv=False)\n","            x=x.reshape(formlist[i]['shape'])\n","            x=torch.tensor(x,dtype=torch.float32)\n","            dlist.append(x)\n","        return dlist\n","\n","    def torch2np(self,xtorch,formlist):\n","        dlist=[]\n","        for i,x in enumerate(xtorch):\n","            if torch.cuda.is_available():\n","                x=x.cpu().detach().numpy()\n","            else:\n","                x=x.detach().numpy()\n","            # if ('pre' in formlist[i]) and (formlist[i]['pre'] in self.pre):\n","                # print([formlist[i]['pre']])\n","                # print(self.pre)\n","                # x=self.pre[formlist[i]['pre']](x,inv=False)\n","            # x=x.reshape(formlist[i]['shape'])\n","            dlist.append(x)\n","        return dlist\n","\n","    # def stack(self,x,inv):\n","        # if not inv:\n","            # #not inv, np2torch\n","            # x=np.swapaxes(x,0,-1)\n","            # xr=x.real\n","            # xi=x.imag\n","            # size=list(x.shape)\n","            # size[0]*=2\n","            # size=tuple(size)\n","            # z=np.zeros(size)\n","            # z[0::2]=xr\n","            # z[1::2]=xi\n","            # z=np.swapaxes(z,0,-1)\n","        # else:\n","            #inv, torch2np\n","            # #size=[B,C,H,W,(T)],numpy\n","            # x=np.swapaxes(x,0,-1)\n","            # xr=x[0::2]\n","            # xi=x[1::2]\n","            # z=xr+1j*xi\n","            # z=np.swapaxes(z,0,-1)\n","\n","        return x\n","\n","    # def concat(self,x,inv):\n","        # if not inv:\n","            #not inv, np2torch\n","            # z=np.concatenate((x.real,x.imag),axis=-1)\n","        # else:\n","            #inv, torch2np\n","            #size=[B,C,H,W,(T)],numpy\n","            # x=np.swapaxes(x,0,-1)\n","            # n=x.shape[0]\n","            # nh=int(n/2)\n","            # xr=x[0:nh]\n","            # xi=x[nh:n]\n","            # z=xr+1j*xi\n","            # z=np.swapaxes(z,0,-1)\n","\n","        return z\n","\n","    def ch2(self,x,inv):\n","        pass\n"]},{"cell_type":"markdown","metadata":{"id":"Bct_Vs-aP3be"},"source":["## Player.py"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"aborted","timestamp":1696836126902,"user":{"displayName":"Talha Ahmed","userId":"17372384323512083426"},"user_tz":-300},"id":"soMmluXI3mNk"},"outputs":[],"source":["# Player.py\n","\n","# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Thu Aug  2 15:43:10 2018\n","\n","@author: Yi Zhang\n","\"\"\"\n","\n","# import numpy as np\n","# import matplotlib.pyplot as plt\n","# import torch\n","\n","minDBdf=-50\n","class Player:\n","    def __init__(self,Tpause=None):\n","        if Tpause==None:\n","            self.Tpause=0.1\n","        else:\n","            self.Tpause=Tpause\n","        self.fig=None\n","        self.ax={1:None,2:None,3:None,4:None,5:None,6:None}\n","        self.axnum=0\n","\n","    def plotmat(self,mvlist,note=None,tit=None,supt=None,\n","                cmap='gray',ion=True,minDB=None):\n","        \"\"\"\n","        input:matrix dimension\n","        \"\"\"\n","        if minDB is None:\n","            minDB=minDBdf\n","\n","        if ion:\n","            plt.ion()\n","\n","        # print('In function plotmat')\n","        subp={1:[1,1],2:[1,2],3:[1,3],4:[2,2],5:[2,3],6:[2,3],9:[3,3],12:[4,3]}\n","        # print('len(mvlist)',len(mvlist))\n","        p1,p2=subp[len(mvlist)]\n","        # print('p1,p2',p1,p2)\n","        if p1*p2!=self.axnum or self.fig is None or not(plt.fignum_exists(self.fig.number)):\n","            'in this if statement'\n","            self.fig,(self.ax)=plt.subplots(p1,p2)\n","            self.axnum=p1*p2\n","            if self.axnum==1:\n","                self.ax=np.array([self.ax])\n","            self.ax=self.ax.reshape([-1])\n","\n","        for i in range(len(mvlist)):\n","            US=mvlist[i]\n","            # print('i of mvlist',i)\n","            if US is None:\n","                continue\n","            if US.dtype is torch.float32:\n","                US=US.detach().numpy()\n","                # 'in this if statement 2'\n","            # print ('US.shape',US.shape)\n","            US=np.abs(US) #.reshape([-1,mvlist[i].shape[-1]])\n","            # US = np.transpose(US, (1, 2, 0))\n","            if np.sum(np.abs(US))!=0:\n","                US=US/np.max(US)\n","            if note=='db':\n","                US[US<10**(minDB/20)]=10**(minDB/20)\n","                US=20*np.log10(US)\n","            vmin,vmax=[minDB,0] if note=='db' else [0,1]\n","            self.ax[i].clear()\n","            self.ax[i].imshow(US)\n","            if not(tit is None):\n","                self.ax[i].set_title(tit[i])\n","        if not(supt is None):\n","            self.fig.suptitle(supt)\n","        if ion:\n","            plt.pause(self.Tpause)\n","        return self.fig\n","\n","    def play(self,mvlist,note=None,tit=None,supt=None,cmap='gray',minDB=None):\n","        \"\"\"\n","        input:movie dimension\n","        \"\"\"\n","        if minDB is None:\n","            minDB=minDBdf\n","\n","        subp={1:[1,1],2:[1,2],3:[1,3],4:[2,2],5:[2,3],6:[2,3],9:[3,3]}\n","        p1,p2=subp[len(mvlist)]\n","        T=mvlist[0].shape[-1]\n","        fig,ax=plt.subplots(p1,p2)\n","        if p1*p2==1:\n","            ax=np.array([ax])\n","        ax=ax.reshape([-1])\n","\n","        plt.ion()\n","\n","        for i in range(len(mvlist)):\n","            US=mvlist[i]\n","            if US is None:\n","                continue\n","            if US.dtype is torch.float32:\n","                US=US.detach().numpy().squeeze()\n","\n","            US=np.abs(US)\n","            if np.sum(np.abs(US))!=0:\n","                US=US/np.max(US)\n","            if note=='db':\n","                US[US<10**(minDB/20)]=10**(minDB/20)\n","                US=20*np.log10(US)\n","            mvlist[i]=US\n","\n","        for t in range(T):\n","            for i in range(len(mvlist)):\n","                if mvlist[i] is None:\n","                    continue\n","                vmin,vmax=[minDB,0] if note=='db' else [0,1]\n","                ax[i].clear()\n","                ax[i].imshow(mvlist[i][:,:,t],cmap=cmap,aspect='auto',\n","                             vmin=vmin,vmax=vmax)\n","                if not(tit is None):\n","                    ax[i].set_title(tit[i])\n","            if supt==None:\n","                supt=''\n","            fig.suptitle('%dth Frame,'%(t+1)+supt)\n","            plt.pause(self.Tpause)\n"]},{"cell_type":"markdown","metadata":{"id":"GaBoRmz1i4ct"},"source":["## My UnfoldedNet2dC.py"]},{"cell_type":"markdown","metadata":{"id":"LaZDvVbK5b1q"},"source":["# Colab"]},{"cell_type":"markdown","metadata":{"id":"24abWA7yyU5Q"},"source":["#### DataSet_Unfolded for Real World Sensing Data.py"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"aborted","timestamp":1696836126902,"user":{"displayName":"Talha Ahmed","userId":"17372384323512083426"},"user_tz":-300},"id":"zwYsPMqG68M6"},"outputs":[],"source":["# Setting up some global variables\n","\n","ROOT = '/content/drive/MyDrive/DUPA - RCPA/Technology transfer deep unfolding/SPROJ-ConvMC-Net/Sensor Data'\n","TRY = '5st try'\n","SESSION = 'Session 5'"]},{"cell_type":"markdown","metadata":{"id":"reS6gl1b1M70"},"source":["#### Model path of loading"]},{"cell_type":"markdown","metadata":{"id":"RGsjtUu7-iJ5"},"source":["Testing Training Loop"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"aborted","timestamp":1696836126902,"user":{"displayName":"Talha Ahmed","userId":"17372384323512083426"},"user_tz":-300},"id":"nOIBCr5gIr8Y"},"outputs":[],"source":["# Get parameters\n","def get_default_param(hyper_param_net, gpu = True):\n","    params_net = {}\n","    if hyper_param_net['Model'] == 'ADMM-Net':\n","        params_net['layers'] = 5\n","\n","        params_net['initial_neta'] = 1.81    # fixed\n","        params_net['initial_lamda1'] = 0.051 # fixed\n","        params_net['initial_lamda2'] = 0.049 # fixed\n","        params_net['initial_v'] = 0\n","\n","        params_net['initial_S'] = 0.05001 #fixed\n","\n","        params_net['initial_P'] = 0.2401 #fixed\n","\n","        params_net['initial_rho'] = 0.1001\n","\n","        params_net['coef_gamma'] = 0.4001\n","\n","        params_net['CalInGPU'] = gpu #whether to calculate in GPU\n","        params_net['size1'] = 400\n","        params_net['size2'] = 500\n","\n","    else:\n","        params_net['layers'] = 5 #1 #2 #3 #4 #5 #6 #7 #8 #9 #10\n","        params_net['kernel'] = [(3, 1)] * 3 + [(3, 1)] * 7\n","        params_net['initial_mu_inverse'] = 0.0\n","\n","        params_net['initial_y1']= 0.8\n","\n","        params_net['coef_mu_inverse'] = 0.36\n","\n","        params_net['CalInGPU'] = gpu # whether to calculate in GPU\n","        params_net['kernel'] = params_net['kernel'][0:params_net['layers']]\n","        params_net['size1'] = 400\n","        params_net['size2'] = 500\n","\n","    return params_net"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"aborted","timestamp":1696836126902,"user":{"displayName":"Talha Ahmed","userId":"17372384323512083426"},"user_tz":-300},"id":"UzUDa_aKur2g"},"outputs":[],"source":["import scipy.io\n","import numpy as np\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","\n","# Define custom PyTorch Dataset class\n","class CustomDataset(Dataset):\n","    def __init__(self, mat_file_M, mat_file_M_Omega):\n","        # Load the .mat files\n","        data_M = scipy.io.loadmat(mat_file_M)\n","        data_M_Omega = scipy.io.loadmat(mat_file_M_Omega)\n","\n","        # Extract the data arrays\n","        self.M = torch.from_numpy(data_M[list(data_M.keys())[-1]]).float()\n","        self.M = self.M.permute(2, 0, 1)\n","        self.M_Omega = torch.from_numpy(data_M_Omega[list(data_M_Omega.keys())[-1]]).float()\n","        self.M_Omega = self.M_Omega.permute(2, 0, 1)\n","\n","    def __len__(self):\n","        return len(self.M)\n","\n","    def __getitem__(self, idx):\n","        return self.M[idx], self.M_Omega[idx]\n","\n","# Define file paths for the training and test datasets\n","train_M_file = 'M_train1.mat'\n","train_M_Omega_file = 'M_Omega_train1.mat'\n","test_M_file = 'M_test1.mat'\n","test_M_Omega_file = 'M_Omega_test1.mat'\n","\n","# Create CustomDataset instances for training and test data\n","train_dataset = CustomDataset(train_M_file, train_M_Omega_file)\n","test_dataset = CustomDataset(test_M_file, test_M_Omega_file)\n","\n","# Create PyTorch DataLoader instances for training and test data\n","batch_size = 4  # You can adjust this as needed\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","# Example usage of the DataLoader\n","for batch in train_loader:\n","    M, M_Omega = batch\n","    # M contains ground truth data\n","    # M_Omega contains noisy/sampled data\n","    # You can perform your training or testing operations here\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"aborted","timestamp":1696836126903,"user":{"displayName":"Talha Ahmed","userId":"17372384323512083426"},"user_tz":-300},"id":"Vd1ddFp_41V_"},"outputs":[],"source":["M, M_Omega = next(iter(test_loader))\n","M.shape, M_Omega.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":653},"executionInfo":{"elapsed":415,"status":"error","timestamp":1696360284646,"user":{"displayName":"Talha Ahmed","userId":"17372384323512083426"},"user_tz":-300},"id":"bmMuNqIs97hm","outputId":"ebed6b71-2dc9-42fe-b8e7-399ecf985c27"},"outputs":[{"name":"stdout","output_type":"stream","text":["Project Name: 5st try 2023-10-04 00:11:23 ConvMC-Net Sampling Rate: 50.0% and Noise Variance 3.0\n","Configuring Network...\n","\n","Instantiating Model...\n","\n","Model Instantiated...\n","\n","Parameters = \n","{'layers': 5, 'kernel': [(3, 1), (3, 1), (3, 1), (3, 1), (3, 1)], 'initial_mu_inverse': 0.0, 'initial_y1': 0.8, 'coef_mu_inverse': 0.36, 'CalInGPU': True, 'size1': 400, 'size2': 500}\n","\n","Loading Data phase...\n","----------------\n","Finished loading.\n","\n","Adjusting learning rate of group 0 to 1.2000e-02.\n","Epoch: 1, 2023-10-04 00:11:23, \n","\n"]},{"ename":"RuntimeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-39-ca354f222db4>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m           \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test time is %f\\n'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendtime\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstartime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mloss_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_lowrank_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCalInGPU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyper_param_net\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Alpha'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyper_param_net\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TrainInstances'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyper_param_net\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'BatchSize'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mloss_val_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_val_lowrank_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCalInGPU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyper_param_net\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Alpha'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyper_param_net\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ValInstances'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyper_param_net\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ValBatchSize'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/py_scripts/training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(model, dataloader, loss_fn, optimizer, CalInGPU, Alpha, TrainInstances, batch, inference)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/py_scripts/convmc.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/py_scripts/convmc.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, lst)\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (500) must match the size of tensor b (60) at non-singleton dimension 1"]}],"source":["# Some settings for visualisation\n","matplotlib.use('Agg')\n","%matplotlib inline\n","\n","seed = 123\n","torch.manual_seed(seed)\n","\n","# Set parameters (including hyperparameters) and setting for saving/logging data\n","\n","hyper_param_net = training.get_hyperparameter_grid('ConvMC-Net', TrainInstances = 40, ValInstances = 20, BatchSize = 4, ValBatchSize = 4, Alpha = 1.0, num_epochs = 40, learning_rate = 0.012)\n","\n","params_net = get_default_param(hyper_param_net, True)\n","\n","CalInGPU = params_net['CalInGPU']\n","\n","q_list = [0.5]\n","sigma_list = [3.0]\n","\n","for q in q_list:\n","  for sigma in sigma_list:\n","    ProjectName = TRY + ' ' + logs_and_results.get_current_time() + ' ' + hyper_param_net['Model'] + ' ' + 'Sampling Rate: ' + logs_and_results.get_q_str(q) + ' and Noise Variance ' + logs_and_results.get_noise_str(sigma)\n","\n","    # Get log file\n","    logfile = logs_and_results.get_modularized_record(ProjectName, q, sigma, 'Logs', hyper_param_net, params_net, SESSION)\n","    log = open(logfile, 'w')\n","    print('Project Name: %s'%ProjectName)\n","    log.write('Project Name: %s\\n'%ProjectName)\n","\n","    # Get Model\n","    net = training.get_model(params_net, hyper_param_net, log)\n","    print('Parameters = \\n%s\\n'%str(params_net))\n","    log.write('params_net=\\n%s\\n\\n'%str(params_net))\n","\n","    #Loading data and creating dataloader for both test and training\n","    print('Loading Data phase...')\n","    print('----------------')\n","    log.write('Loading phase...\\n')\n","    log.write('----------------\\n')\n","    shape_dset = (params_net['size1'], params_net['size2'])\n","    # train_dataset = dataset_processing.ImageDataset(round(hyper_param_net['TrainInstances']), shape_dset, 0, q, sigma)\n","    # train_loader = data.DataLoader(train_dataset,batch_size = hyper_param_net['BatchSize'], shuffle = True)\n","    # val_dataset = dataset_processing.ImageDataset(round(hyper_param_net['ValInstances']), shape_dset, 1, q, sigma)\n","    # test_loader = data.DataLoader(val_dataset, batch_size = hyper_param_net['ValBatchSize'], shuffle = True)\n","    print('Finished loading.\\n')\n","    log.write('Finished loading.\\n\\n');\n","\n","    # Some additional settings for training including loss, optimizer,\n","    floss = nn.MSELoss()\n","    optimizer = torch.optim.Adam(net.parameters(), lr = hyper_param_net['Lr'])\n","    scheduler2 =  torch.optim.lr_scheduler.StepLR(optimizer, step_size= 1, gamma = 0.97, verbose = True)\n","\n","    # Array for recording parameter values after each layer for each epoch etc\n","    outputs_L = convmc.to_var(torch.zeros([shape_dset[0], shape_dset[1]]), CalInGPU)\n","    lossmean_vec = np.zeros((hyper_param_net['Epochs'], ))\n","    lossmean_val_vec = np.zeros((hyper_param_net['Epochs'], ))\n","\n","    mu_inverse, y1, exp_L = net.getexp_LS()\n","\n","    mu_inverse_vec = np.zeros((hyper_param_net['Epochs'], net.layers))\n","    y1_vec = np.zeros((hyper_param_net['Epochs'], net.layers,params_net['size1'], params_net['size2']))\n","    exp_L_vec = np.zeros((hyper_param_net['Epochs'], net.layers))\n","\n","    # dummy variable to monitor and record progress for loss\n","    minloss = np.inf\n","\n","    for epoch in range(hyper_param_net['Epochs']):\n","      print(f'Epoch: {epoch + 1}, {logs_and_results.get_current_time()}, \\n')\n","      log.write('\\n' + logs_and_results.get_current_time() + '\\n')\n","\n","      # Train and Test Steps. (Record every 5 epochs)\n","      if (epoch + 1) % 5 == 0:\n","          print('Loading and calculating training batches...')\n","          log.write('Loading and calculating training batches...\\n')\n","          startime = time.time()\n","          loss_mean, loss_lowrank_mean = training.train_step(net, train_loader, floss, optimizer, CalInGPU, hyper_param_net['Alpha'], hyper_param_net['TrainInstances'], hyper_param_net['BatchSize'])\n","          endtime = time.time()\n","          print('Training time is %f'%(endtime - startime))\n","          log.write('Training time is %f\\n'%(endtime - startime))\n","\n","          print('Loading and calculating validation batches...')\n","          log.write('Loading and calculating validation batches...\\n')\n","          startime = time.time()\n","          loss_val_mean, loss_val_lowrank_mean = training.test_step(net, test_loader, floss, optimizer, CalInGPU, hyper_param_net['Alpha'], hyper_param_net['ValInstances'], hyper_param_net['ValBatchSize'])\n","          endtime = time.time()\n","          print('Test time is %f'%(endtime - startime))\n","          log.write('Test time is %f\\n'%(endtime - startime))\n","      else:\n","        loss_mean, loss_lowrank_mean = training.train_step(net, train_loader, floss, optimizer, CalInGPU, hyper_param_net['Alpha'], hyper_param_net['TrainInstances'], hyper_param_net['BatchSize'])\n","        loss_val_mean, loss_val_lowrank_mean = training.test_step(net, test_loader, floss, optimizer, CalInGPU, hyper_param_net['Alpha'], hyper_param_net['ValInstances'], hyper_param_net['ValBatchSize'])\n","\n","      # Update Record and Parameters\n","      lossmean_vec[epoch] = loss_mean\n","      lossmean_val_vec[epoch] = loss_val_mean\n","\n","      mu_inverse, y1, exp_L = net.getexp_LS()\n","\n","      mu_inverse_vec[epoch, :] = mu_inverse\n","      y1_vec[epoch] = y1\n","      exp_L_vec[epoch, :] = exp_L\n","\n","      # Update Log after every 5 epochs. Make a plot of MSE against epochs every 5 epochs. Save Model in whole/dict form every five epochs.\n","      if (epoch + 1) % 5 == 0:\n","        print(f\"Saving Whole Model at Epochs: [{epoch + 1}/{hyper_param_net['Epochs']}]\")\n","        model_whole_path = logs_and_results.get_modularized_record(ProjectName, q, sigma, 'Saved Models - Whole', hyper_param_net, params_net, SESSION, current_epoch = epoch + 1)\n","        torch.save(net, model_whole_path)\n","        print(f\"Saving Model Dict at Epochs: [{epoch + 1}/{hyper_param_net['Epochs']}]\")\n","        model_state_dict_path = logs_and_results.get_modularized_record(ProjectName, q, sigma, 'Saved Models - Dict', hyper_param_net, params_net, SESSION, current_epoch = epoch + 1)\n","        torch.save(net.state_dict(), model_state_dict_path)\n","\n","        print('Epoch [%d/%d], Lossmean:%.5e, Validation lossmean:%.5e'\n","              %(epoch + 1, hyper_param_net['Epochs'], loss_mean, loss_val_mean))\n","        print('loss_lowrank_mean', loss_lowrank_mean)\n","        print('loss_val_lowrank_mean', loss_val_lowrank_mean)\n","\n","        log.write('loss_lowrank_mean %.5e\\n' %(loss_lowrank_mean))\n","        log.write('loss_val_lowrank_mean %.5e\\n' %(loss_val_lowrank_mean))\n","        log.write('Epoch [%d/%d], Lossmean:%.5e, Validation lossmean:%.5e\\n'\n","              %(epoch + 1, hyper_param_net['Epochs'], loss_mean, loss_val_mean))\n","        np.set_printoptions(precision = 3)\n","\n","        print('mu_inverse:', mu_inverse)\n","\n","        print('torch.mean(y1)', np.mean(y1))\n","        print('y1:', y1)\n","        print('exp_L:', exp_L)\n","\n","        log.write('mu_inverse: '+ str(mu_inverse)+'\\n')\n","        log.write('y1: '+ str(y1)+'\\n')\n","        log.write('exp_L: '+ str(exp_L) + '\\n')\n","\n","        if True or loss_val_mean<minloss:\n","          print('saved at [epoch%d/%d]'%(epoch + 1, hyper_param_net['Epochs']))\n","          log.write('saved at [epoch%d/%d]\\n' %(epoch + 1, hyper_param_net['Epochs']))\n","          minloss = min(loss_val_mean, minloss)\n","\n","        # Plotting MSE vs Epoch and Saving it\n","\n","        # Get Directory where we have to save the plot\n","        dir = logs_and_results.get_modularized_record(ProjectName, q, sigma, 'Plots', hyper_param_net, params_net, SESSION, current_epoch = epoch + 1)\n","        epochs_vec = np.arange(0, hyper_param_net['Epochs'], 1)\n","        logs_and_results.plot_and_save_mse_vs_epoch(epochs_vec, lossmean_vec, hyper_param_net, lossmean_val_vec, dir, epoch)\n","\n","    # Finish off by observing the minimum loss on validation set\n","\n","    #Print min loss\n","    print('\\nmin Loss = %.4e'%np.min(lossmean_val_vec))\n","    log.write('\\nmin Loss = %.4e\\n'%np.min(lossmean_val_vec))\n","    log.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1693990070987,"user":{"displayName":"Talha Ahmed","userId":"17372384323512083426"},"user_tz":-300},"id":"YpAGyze3rR2j","outputId":"4454fa41-df4f-4266-d7ba-74866f47a161"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/DUPA - RCPA/Technology transfer deep unfolding/SPROJ-ConvMC-Net/Sensor Data'"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["ROOT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K75C6tH2p4To"},"outputs":[],"source":["!cp -r '/content/drive/MyDrive/DUPA - RCPA/Technology transfer deep unfolding/SPROJ-ConvMC-Net/Sensor Data' '/content/convmc-net'\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0CbwzktNp8EQ"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"}},"nbformat":4,"nbformat_minor":0}
