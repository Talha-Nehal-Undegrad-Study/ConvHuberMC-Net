{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Original saved in Tahir Sproj folder\n",
    "\n",
    "# Deep Learning Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data\n",
    "\n",
    "# Data Manipulation and Analysis\n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# File and System Interaction\n",
    "import os\n",
    "from pathlib import Path\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# Date and Time Handling\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# Neural Architecture\n",
    "try:\n",
    "    from torchinfo import summary\n",
    "except:\n",
    "    # %pip install torchinfo\n",
    "    from torchinfo import summary\n",
    "from scipy.fftpack import dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# from python_scripts import dataset_processing\n",
    "# from python_scripts import architecture\n",
    "# from python_scripts import revised_architecture\n",
    "# from python_scripts import training\n",
    "# from python_scripts import logs_and_results\n",
    "# from python_scripts import img_pdf_compiler\n",
    "from python_scripts import utils\n",
    "from python_scripts import DUST_MC\n",
    "from python_scripts import dustmc_unrolled\n",
    "from python_scripts import test\n",
    "from python_scripts import generate_synthetic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 889.3987, -400.7791,  701.3297, 1246.3589,  -66.9305, -652.9890,\n",
      "         -238.3193,  -70.9368,  654.4198,  337.0663],\n",
      "        [ 230.4068, -349.2725,   67.1426,  317.9235,  -43.7342, -118.5419,\n",
      "          -41.4297,  -64.4256,  144.0345,  286.7173],\n",
      "        [ 819.9326, -348.4921,  563.7321, 1431.6442, -156.5717, -512.8481,\n",
      "         -189.2724,  -44.1213,  656.7279,  340.4797]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "model = dustmc_unrolled.DustNet(K=5, mu=0, sigma=1, m=3, n=3, d=3, T=10)\n",
    "S = torch.randn(3, 10)\n",
    "output = model(S)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta_i: tensor([0.0045, 0.0176, 0.0199, 0.0003, 0.0161])\n",
      "Indexed value: 0.01992465741932392\n",
      "Type of indexed value: <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Example values\n",
    "DH = torch.randn(10, 5)  # Shape (n, T)\n",
    "\n",
    "# Compute Î²i values\n",
    "beta_i = torch.exp(-0.5 * torch.sum(DH ** 2, dim=0))  # Shape (T,)\n",
    "\n",
    "# Ensure indexing returns a tensor\n",
    "index = 2\n",
    "indexed_value = beta_i[index]\n",
    "\n",
    "print(f\"beta_i: {beta_i}\")\n",
    "print(f\"Indexed value: {indexed_value}\")\n",
    "print(f\"Type of indexed value: {type(indexed_value)}\")  # Should be <class 'torch.Tensor'>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get relevant arguements for DUSTMC\n",
    "\n",
    "M_train, M_Omega_train, M_test, M_Omega_test = generate_synthetic_data.generate_simple_gaussian_noise(150, 300, 10, 10, 2, 0.5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "# np.random.seed(42)\n",
    "\n",
    "rand_batch_idx = np.random.randint(0, M_Omega_train.shape[0])\n",
    "X = M_Omega_train[rand_batch_idx, :, :]\n",
    "\n",
    "# Initialize a m x n A measurement sensing matrix with random values from a uniform distribution between 0 and 1\n",
    "A = np.random.uniform(0, 1, (100, 150)) # A is m x n. Since m << n and n is normally 150\n",
    "\n",
    "# Initalize the Dictonary D which is n x d and d >> n by DCT. d is taken as 512\n",
    "random_matrix = np.random.uniform(0, 1, (150, 512))\n",
    "\n",
    "# Apply the Discrete Cosine Transform (DCT) to the matrix\n",
    "D = dct(random_matrix, type = 2, norm = 'ortho')\n",
    "\n",
    "# Initialize K (no. of iterations), and hyperparameters lambda_1, lambda_2, and c\n",
    "K = 50\n",
    "lambda_1 = 0.1\n",
    "lambda_2 = 0.4\n",
    "c = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Talha\\AppData\\Local\\Temp\\ipykernel_20176\\157688921.py:35: RuntimeWarning: overflow encountered in exp\n",
      "  exp_values = np.exp(exponent_terms)\n",
      "C:\\Users\\Talha\\AppData\\Local\\Temp\\ipykernel_20176\\157688921.py:38: RuntimeWarning: invalid value encountered in multiply\n",
      "  G_numerator = np.sum(beta_values[:, None] * exp_values[:, None] * H.T, axis=0)\n",
      "C:\\Users\\Talha\\AppData\\Local\\Temp\\ipykernel_20176\\157688921.py:39: RuntimeWarning: invalid value encountered in multiply\n",
      "  G_denominator = np.sum(beta_values * exp_values)\n"
     ]
    }
   ],
   "source": [
    "# Now run the attention based algo on X to get its recovered/reconstructed form S\n",
    "S = test.attention_based_algo(A, D, X, K, lambda_1, lambda_2, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now measure loss between reconstructed and groundtruth\n",
    "\n",
    "groundtruth = M_train[rand_batch_idx, :, :]\n",
    "\n",
    "print(f'The squared L2 norm loss is: {utils.compute_squared_l2_norm_loss(S, groundtruth)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
